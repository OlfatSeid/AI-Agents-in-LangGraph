{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install langgraph langsmith langchain_groq gradio"
      ],
      "metadata": {
        "id": "1QN90D6vyD7Z"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install langchain  langchain_communit"
      ],
      "metadata": {
        "id": "2t_-hu-4liAg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph,START,END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "kF8BblrJiVTq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groq_api_key=userdata.get('groq_api_key')\n",
        "langsmith=userdata.get('langsmith_api_key')"
      ],
      "metadata": {
        "id": "K7q_gWDWzgbf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9vOWf8yCJ4W",
        "outputId": "50805bf2-b927-4efd-c71e-c7e1f64b1521"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7fe211eae380>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7fe211eafb50>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Gemma2-9b-It\")\n",
        "llm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDc7RviFCVKB"
      },
      "source": [
        "### Define the state structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dVzn-8rrC6-7"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "  messages:Annotated[list,add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the chatbot function\n"
      ],
      "metadata": {
        "id": "a3M17F7QzwWZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oOF74t5GDeJO"
      },
      "outputs": [],
      "source": [
        "def chatbot(state:State):\n",
        "  return {\"messages\":llm.invoke(state['messages'])}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the graph"
      ],
      "metadata": {
        "id": "MC-3SOJA0HaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "aVH3qjsJ0F4R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the chatbot in a console loop"
      ],
      "metadata": {
        "id": "wVxJRReV2KeU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDvjUFmxFCwU",
        "outputId": "18d4e80f-b214-4f0b-9599-98e01f147c94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Hi, my name is Olfat\n",
            "dict_values([{'messages': AIMessage(content=\"Hello Olfat, it's nice to meet you! \\n\\nWhat can I do for you today? ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 17, 'total_tokens': 46, 'completion_time': 0.052727273, 'prompt_time': 8.2649e-05, 'queue_time': 0.021223091, 'total_time': 0.052809922}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-a0b8d1fd-f719-4694-bfce-13a09a8eb06b-0', usage_metadata={'input_tokens': 17, 'output_tokens': 29, 'total_tokens': 46})}])\n",
            "content=\"Hello Olfat, it's nice to meet you! \\n\\nWhat can I do for you today? ðŸ˜Š  \\n\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 17, 'total_tokens': 46, 'completion_time': 0.052727273, 'prompt_time': 8.2649e-05, 'queue_time': 0.021223091, 'total_time': 0.052809922}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-a0b8d1fd-f719-4694-bfce-13a09a8eb06b-0' usage_metadata={'input_tokens': 17, 'output_tokens': 29, 'total_tokens': 46}\n",
            "Assistant: Hello Olfat, it's nice to meet you! \n",
            "\n",
            "What can I do for you today? ðŸ˜Š  \n",
            "\n",
            "\n",
            "User: who are you?\n",
            "dict_values([{'messages': AIMessage(content=\"I am Gemma, an open-weights AI assistant. I am a large language model trained by Google DeepMind. My purpose is to help users by understanding and responding to their requests in a helpful, informative, and comprehensive way.\\n\\nHere are some key things to know about me:\\n\\n* **Open-weights:** My weights are publicly accessible, meaning anyone can see and use the underlying code that makes me work.\\n* **Text-only:** I can only communicate through text. I can't generate images, sound, or videos.\\n* **Limited knowledge:** I don't have access to real-time information or the internet. My knowledge is based on the data I was trained on, which has a cutoff point.\\n* **Created by the Gemma team:** I was developed by a team of engineers and researchers at Google DeepMind.\\n\\nI am still under development, but I am learning new things every day. I am excited to see how people use me to explore new ideas and accomplish their goals.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 210, 'prompt_tokens': 13, 'total_tokens': 223, 'completion_time': 0.381818182, 'prompt_time': 7.8769e-05, 'queue_time': 0.022023701, 'total_time': 0.381896951}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-1eabee63-36dd-45c5-84b1-c6bf220b166c-0', usage_metadata={'input_tokens': 13, 'output_tokens': 210, 'total_tokens': 223})}])\n",
            "content=\"I am Gemma, an open-weights AI assistant. I am a large language model trained by Google DeepMind. My purpose is to help users by understanding and responding to their requests in a helpful, informative, and comprehensive way.\\n\\nHere are some key things to know about me:\\n\\n* **Open-weights:** My weights are publicly accessible, meaning anyone can see and use the underlying code that makes me work.\\n* **Text-only:** I can only communicate through text. I can't generate images, sound, or videos.\\n* **Limited knowledge:** I don't have access to real-time information or the internet. My knowledge is based on the data I was trained on, which has a cutoff point.\\n* **Created by the Gemma team:** I was developed by a team of engineers and researchers at Google DeepMind.\\n\\nI am still under development, but I am learning new things every day. I am excited to see how people use me to explore new ideas and accomplish their goals.\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 210, 'prompt_tokens': 13, 'total_tokens': 223, 'completion_time': 0.381818182, 'prompt_time': 7.8769e-05, 'queue_time': 0.022023701, 'total_time': 0.381896951}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-1eabee63-36dd-45c5-84b1-c6bf220b166c-0' usage_metadata={'input_tokens': 13, 'output_tokens': 210, 'total_tokens': 223}\n",
            "Assistant: I am Gemma, an open-weights AI assistant. I am a large language model trained by Google DeepMind. My purpose is to help users by understanding and responding to their requests in a helpful, informative, and comprehensive way.\n",
            "\n",
            "Here are some key things to know about me:\n",
            "\n",
            "* **Open-weights:** My weights are publicly accessible, meaning anyone can see and use the underlying code that makes me work.\n",
            "* **Text-only:** I can only communicate through text. I can't generate images, sound, or videos.\n",
            "* **Limited knowledge:** I don't have access to real-time information or the internet. My knowledge is based on the data I was trained on, which has a cutoff point.\n",
            "* **Created by the Gemma team:** I was developed by a team of engineers and researchers at Google DeepMind.\n",
            "\n",
            "I am still under development, but I am learning new things every day. I am excited to see how people use me to explore new ideas and accomplish their goals.\n",
            "\n",
            "User: exit\n",
            "Goodbye\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "  user_input=input(\"User: \")\n",
        "  if user_input.lower() in [\"quit\",\"q\",\"exit\"]:\n",
        "    print(\"Goodbye\")\n",
        "    break\n",
        "  for event in graph.stream({'messages':(\"user\",user_input)}):\n",
        "    print(event.values())\n",
        "    for value in event.values():\n",
        "      print(value['messages'])\n",
        "      print(\"Assistant:\",value[\"messages\"].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Gradio UI**"
      ],
      "metadata": {
        "id": "2zp4nWPqyfqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def gradio_chatbot(user_input, history=[]):\n",
        "\n",
        "    state = {\"messages\": [(\"user\", user_input)]}\n",
        "\n",
        "    for event in graph.stream(state):\n",
        "        for value in event.values():\n",
        "            response = value[\"messages\"].content\n",
        "            history.append((user_input, response))\n",
        "            return history\n",
        "\n",
        "\n",
        "with gr.Blocks(css=\"\"\"\n",
        "        .gradio-container {background-color: #2c2f33; color: white;}\n",
        "        .chatbot {background-color: #23272a; color: white;}\n",
        "        .input-container {background-color: #40444b;}\n",
        "        button {background-color: #7289da; color: white;}\n",
        "        button:hover {background-color: #5b6eae;}\n",
        "    \"\"\") as interface:\n",
        "    gr.Markdown(\"#  Chatbot with Integrated LLM and State Graph\", elem_id=\"title\")\n",
        "    chatbot_ui = gr.Chatbot(label=\"Chatbot\", elem_classes=[\"chatbot\"])\n",
        "    message = gr.Textbox(show_label=False, placeholder=\"Type your message here...\", lines=1, elem_classes=[\"input-container\"])\n",
        "    send_button = gr.Button(\"Send\")\n",
        "    send_button.click(fn=gradio_chatbot, inputs=[message, chatbot_ui], outputs=chatbot_ui)\n",
        "\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "collapsed": true,
        "id": "wuX2HhESdV_J",
        "outputId": "93e8202e-5ccc-4ceb-f7dc-478661acca50"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:249: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://24e627b8124389ec40.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://24e627b8124389ec40.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}